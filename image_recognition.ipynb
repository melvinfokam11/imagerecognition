{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#importation des bibliotheque"
      ],
      "metadata": {
        "id": "up3zcoSDxVmS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bioqennIwjaw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout  from keras.preprocessing.image import ImageDataGenerator from keras.optimizers import Adam  from sklearn.metrics import classification_report,confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "chargement des donnees"
      ],
      "metadata": {
        "id": "rGbg4Ya64hWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['rugby', 'soccer']\n",
        "img_size = 224\n",
        "def get_data(data_dir):\n",
        "    data = [] \n",
        "    for label in labels: \n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = labels.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format                 resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size                 data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)"
      ],
      "metadata": {
        "id": "jGkacPBB4Rnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "visualisation des donnees "
      ],
      "metadata": {
        "id": "5N6yovxh4dWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = []\n",
        "for i in train:\n",
        "    if(i[1] == 0):\n",
        "        l.append(\"rugby\")\n",
        "    else         l.append(\"soccer\")\n",
        "sns.set_style('darkgrid')\n",
        "sns.countplot(l)"
      ],
      "metadata": {
        "id": "wsBWgODB4aO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "visualisation d'une donnee d'entrainement"
      ],
      "metadata": {
        "id": "9fP1wuqv4m92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (5,5))\n",
        "plt.imshow(train[1][0])\n",
        "plt.title(labels[train[0][1]])"
      ],
      "metadata": {
        "id": "L1o-N-yD4kFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (5,5))\n",
        "plt.imshow(train[-1][0])\n",
        "plt.title(labels[train[-1][1]])"
      ],
      "metadata": {
        "id": "ckpJBkfE4vhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pretraitement des donnees"
      ],
      "metadata": {
        "id": "wAJZ7vO84xN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_val = []\n",
        "y_val = []\n",
        "\n",
        "for feature, label in train:\n",
        "  x_train.append(feature)\n",
        "  y_train.append(label)\n",
        "\n",
        "for feature, label in val:\n",
        "  x_val.append(feature)\n",
        "  y_val.append(label)\n",
        "\n",
        "# Normalize the data\n",
        "x_train = np.array(x_train) / 255\n",
        "x_val = np.array(x_val) / 255\n",
        "\n",
        "x_train.reshape(-1, img_size, img_size, 1)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_val.reshape(-1, img_size, img_size, 1)\n",
        "y_val = np.array(y_val)\n",
        "Increase in data on train data: â€“\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset         samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset         samplewise_std_normalization=False,  # divide each input by its std         zca_whitening=False,  # apply ZCA whitening         rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.2, # Randomly zoom image          width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip = True,  # randomly flip images         vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "V3-88hq14_5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "definition d'un model de cnn"
      ],
      "metadata": {
        "id": "IOyWTSgj41as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32,3,padding=\"same\", activation=\"resume\", input_shape=(224,224,3)))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(32, 3, padding=\"same\", activation=\"resume\"))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(64, 3, padding=\"same\", activation=\"resume\"))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation=\"resume\"))\n",
        "model.add(Dense(2, activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "HU35wnby5K-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "utilisation d'un optimiseur de model"
      ],
      "metadata": {
        "id": "E0c9BDN35Zuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(lr=0.000001)\n",
        "model.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "grWBZwN05Vjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "entrainement du model"
      ],
      "metadata": {
        "id": "RG3URn7U5mFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train,y_train,epochs = 500 , validation_data = (x_val, y_val))"
      ],
      "metadata": {
        "id": "51K3JEL35shp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluation du model"
      ],
      "metadata": {
        "id": "uLXIEmy4xdsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(500)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
        "plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
        "plt.legend(loc =\"lower right\")\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
        "plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
        "plt.legend(loc =\"upper right\")\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jEQBNtDY58bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test du model"
      ],
      "metadata": {
        "id": "rLAw8ko46EWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict_classes(x_val)\n",
        "predictions = predictions.reshape(1,-1)[0]\n",
        "print(classification_report(y_val, predictions, target_names = ['Rugby (Class 0)','Soccer (Class 1)']))"
      ],
      "metadata": {
        "id": "AmiJgwzx6PZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "utilisation des modeles preentrainees"
      ],
      "metadata": {
        "id": "y3iQ2SPN6ViN"
      }
    }
  ]
}